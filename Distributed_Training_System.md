# 分布式深度学习框架

[toc]

## 背景

​	在[上一篇](./Deep_Learning_Basics.pdf)的结尾简单介绍了分布式深度学习框架的对比，本节主要针对分布式学习过程中的挑战与解决方案进行调研。

### 主要挑战

#### 训练的数据量急剧增加

​	通过增加Batch Size来加速





### 已有实现

#### [Hogwild!](http://d0evi1.com/hogwild/)

​	Hogwild!提供了一种”无锁方式并行运行SGD“。



## 参考

[1] Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent

